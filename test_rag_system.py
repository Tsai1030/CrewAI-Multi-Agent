"""
RAG ç³»çµ±æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ BGE-M3 + GPT-4o RAG ç³»çµ±çš„å„å€‹çµ„ä»¶
"""

import os
import sys
import logging
import traceback
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_environment():
    """æ¸¬è©¦ç’°å¢ƒé…ç½®"""
    print("=== ç’°å¢ƒé…ç½®æ¸¬è©¦ ===")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    required_vars = [
        "OPENAI_API_KEY",
        "EMBEDDING_MODEL", 
        "EMBEDDING_PROVIDER"
    ]
    
    missing_vars = []
    for var in required_vars:
        value = os.getenv(var)
        if value:
            print(f"âœ“ {var}: {'*' * (len(value) - 10) + value[-10:] if len(value) > 10 else value}")
        else:
            print(f"âœ— {var}: æœªè¨­ç½®")
            missing_vars.append(var)
    
    if missing_vars:
        print(f"è­¦å‘Š: ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ {missing_vars}")
        return False
    
    return True


def test_dependencies():
    """æ¸¬è©¦ä¾è³´åŒ…"""
    print("\n=== ä¾è³´åŒ…æ¸¬è©¦ ===")
    
    dependencies = [
        ("torch", "PyTorch"),
        ("transformers", "Transformers"),
        ("tokenizers", "Tokenizers"),
        ("chromadb", "ChromaDB"),
        ("openai", "OpenAI"),
        ("langchain", "LangChain")
    ]
    
    all_available = True
    for package, name in dependencies:
        try:
            __import__(package)
            print(f"âœ“ {name}: å·²å®‰è£")
        except ImportError:
            print(f"âœ— {name}: æœªå®‰è£")
            all_available = False
    
    return all_available


def test_bge_embeddings():
    """æ¸¬è©¦ BGE-M3 åµŒå…¥æ¨¡å‹"""
    print("\n=== BGE-M3 åµŒå…¥æ¨¡å‹æ¸¬è©¦ ===")
    
    try:
        from src.rag.bge_embeddings import BGEM3Embeddings
        
        # å‰µå»ºåµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨è¼ƒå°çš„é…ç½®é€²è¡Œæ¸¬è©¦ï¼‰
        embeddings = BGEM3Embeddings(
            model_name="BAAI/bge-m3",
            device="cpu",
            max_length=512,  # è¼ƒå°çš„é•·åº¦ç”¨æ–¼æ¸¬è©¦
            batch_size=2
        )
        
        # æ¸¬è©¦æ–‡æœ¬åµŒå…¥
        test_texts = [
            "ç´«å¾®æ˜Ÿæ˜¯ç´«å¾®æ–—æ•¸ä¸­çš„å¸ç‹æ˜Ÿ",
            "å¤©æ©Ÿæ˜Ÿä»£è¡¨æ™ºæ…§å’Œè®ŠåŒ–"
        ]
        
        print("æ¸¬è©¦æ–‡æª”åµŒå…¥...")
        doc_embeddings = embeddings.embed_documents(test_texts)
        print(f"âœ“ æ–‡æª”åµŒå…¥æˆåŠŸï¼Œç¶­åº¦: {len(doc_embeddings[0])}")
        
        print("æ¸¬è©¦æŸ¥è©¢åµŒå…¥...")
        query_embedding = embeddings.embed_query("ä»€éº¼æ˜¯ç´«å¾®æ˜Ÿï¼Ÿ")
        print(f"âœ“ æŸ¥è©¢åµŒå…¥æˆåŠŸï¼Œç¶­åº¦: {len(query_embedding)}")
        
        # æ¸¬è©¦æ¨¡å‹ä¿¡æ¯
        model_info = embeddings.get_model_info()
        print(f"âœ“ æ¨¡å‹ä¿¡æ¯: {model_info['model_name']}")
        
        return True
        
    except Exception as e:
        print(f"âœ— BGE-M3 æ¸¬è©¦å¤±æ•—: {str(e)}")
        traceback.print_exc()
        return False


def test_gpt4o_generator():
    """æ¸¬è©¦ GPT-4o ç”Ÿæˆå™¨"""
    print("\n=== GPT-4o ç”Ÿæˆå™¨æ¸¬è©¦ ===")
    
    try:
        from src.rag.gpt4o_generator import GPT4oGenerator
        
        # å‰µå»ºç”Ÿæˆå™¨
        generator = GPT4oGenerator(
            model="gpt-4o",
            temperature=0.7,
            max_tokens=100  # è¼ƒå°çš„ token æ•¸ç”¨æ–¼æ¸¬è©¦
        )
        
        # æ¸¬è©¦ç°¡å–®ç”Ÿæˆ
        test_query = "ä»€éº¼æ˜¯ç´«å¾®æ–—æ•¸ï¼Ÿ"
        test_context = ["ç´«å¾®æ–—æ•¸æ˜¯ä¸­åœ‹å¤ä»£çš„ä¸€ç¨®å‘½ç†å­¸èªª"]
        
        print("æ¸¬è©¦å›ç­”ç”Ÿæˆ...")
        response = generator.generate_response(
            query=test_query,
            context_documents=test_context
        )
        
        if "error" not in response:
            print(f"âœ“ ç”ŸæˆæˆåŠŸ")
            print(f"  å›ç­”é•·åº¦: {len(response['answer'])} å­—ç¬¦")
            print(f"  ä½¿ç”¨ Token: {response.get('usage', {}).get('total_tokens', 'N/A')}")
            return True
        else:
            print(f"âœ— ç”Ÿæˆå¤±æ•—: {response['error']}")
            return False
            
    except Exception as e:
        print(f"âœ— GPT-4o æ¸¬è©¦å¤±æ•—: {str(e)}")
        traceback.print_exc()
        return False


def test_vector_store():
    """æ¸¬è©¦å‘é‡å­˜å„²"""
    print("\n=== å‘é‡å­˜å„²æ¸¬è©¦ ===")
    
    try:
        from src.rag.vector_store import ZiweiVectorStore
        from langchain.schema import Document
        
        # å‰µå»ºå‘é‡å­˜å„²ï¼ˆä½¿ç”¨æ¸¬è©¦é…ç½®ï¼‰
        vector_store = ZiweiVectorStore(
            persist_directory="./data/test_vector_db",
            collection_name="test_collection",
            embedding_provider="huggingface",
            embedding_model="BAAI/bge-m3",
            embedding_config={
                "device": "cpu",
                "max_length": 512,
                "batch_size": 2
            }
        )
        
        # æ¸¬è©¦æ–‡æª”æ·»åŠ 
        test_docs = [
            Document(
                page_content="ç´«å¾®æ˜Ÿæ˜¯ç´«å¾®æ–—æ•¸ä¸­æœ€é‡è¦çš„ä¸»æ˜Ÿä¹‹ä¸€",
                metadata={"category": "ä¸»æ˜Ÿ", "star": "ç´«å¾®æ˜Ÿ"}
            ),
            Document(
                page_content="å¤©æ©Ÿæ˜Ÿä»£è¡¨æ™ºæ…§ã€è®ŠåŒ–å’Œæ©Ÿæ•",
                metadata={"category": "ä¸»æ˜Ÿ", "star": "å¤©æ©Ÿæ˜Ÿ"}
            )
        ]
        
        print("æ¸¬è©¦æ–‡æª”æ·»åŠ ...")
        doc_ids = vector_store.add_documents(test_docs)
        print(f"âœ“ æ·»åŠ æ–‡æª”æˆåŠŸï¼ŒID: {doc_ids}")
        
        # æ¸¬è©¦æœç´¢
        print("æ¸¬è©¦å‘é‡æœç´¢...")
        search_results = vector_store.search("ç´«å¾®æ˜Ÿçš„ç‰¹è³ª", top_k=2)
        print(f"âœ“ æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(search_results)} å€‹çµæœ")
        
        # æ¸¬è©¦çµ±è¨ˆä¿¡æ¯
        stats = vector_store.get_collection_stats()
        print(f"âœ“ çµ±è¨ˆä¿¡æ¯: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âœ— å‘é‡å­˜å„²æ¸¬è©¦å¤±æ•—: {str(e)}")
        traceback.print_exc()
        return False


def test_rag_system():
    """æ¸¬è©¦å®Œæ•´ RAG ç³»çµ±"""
    print("\n=== å®Œæ•´ RAG ç³»çµ±æ¸¬è©¦ ===")
    
    try:
        from src.rag.rag_system import create_rag_system
        
        # å‰µå»ºæ¸¬è©¦é…ç½®
        test_config = {
            "vector_store": {
                "persist_directory": "./data/test_rag_db",
                "collection_name": "test_rag",
                "embedding_provider": "huggingface",
                "embedding_model": "BAAI/bge-m3",
                "embedding_config": {
                    "device": "cpu",
                    "max_length": 512,
                    "batch_size": 2,
                    "openai_fallback": True
                }
            },
            "generator": {
                "model": "gpt-4o",
                "temperature": 0.7,
                "max_tokens": 150
            },
            "rag": {
                "top_k": 3,
                "min_score": 0.5
            }
        }
        
        # å‰µå»º RAG ç³»çµ±
        print("å‰µå»º RAG ç³»çµ±...")
        rag_system = create_rag_system(test_config)
        
        # æª¢æŸ¥ç³»çµ±ç‹€æ…‹
        status = rag_system.get_system_status()
        print(f"âœ“ ç³»çµ±ç‹€æ…‹: {status['system']}")
        
        # æ·»åŠ æ¸¬è©¦çŸ¥è­˜
        print("æ·»åŠ æ¸¬è©¦çŸ¥è­˜...")
        test_knowledge = [
            {
                "content": "ç´«å¾®æ˜Ÿæ˜¯ç´«å¾®æ–—æ•¸çš„ä¸»æ˜Ÿï¼Œä»£è¡¨å¸ç‹ä¹‹æ˜Ÿï¼Œå…·æœ‰é ˜å°èƒ½åŠ›",
                "metadata": {"star": "ç´«å¾®æ˜Ÿ", "type": "ä¸»æ˜Ÿè§£æ"}
            }
        ]
        
        success = rag_system.add_knowledge(test_knowledge)
        if success:
            print("âœ“ çŸ¥è­˜æ·»åŠ æˆåŠŸ")
        else:
            print("âœ— çŸ¥è­˜æ·»åŠ å¤±æ•—")
            return False
        
        # æ¸¬è©¦å•ç­”
        print("æ¸¬è©¦å•ç­”åŠŸèƒ½...")
        response = rag_system.generate_answer(
            query="ç´«å¾®æ˜Ÿæœ‰ä»€éº¼ç‰¹è³ªï¼Ÿ",
            context_type="auto"
        )
        
        if "error" not in response:
            print("âœ“ å•ç­”æ¸¬è©¦æˆåŠŸ")
            print(f"  å›ç­”: {response['answer'][:100]}...")
            return True
        else:
            print(f"âœ— å•ç­”æ¸¬è©¦å¤±æ•—: {response['error']}")
            return False
            
    except Exception as e:
        print(f"âœ— RAG ç³»çµ±æ¸¬è©¦å¤±æ•—: {str(e)}")
        traceback.print_exc()
        return False


def cleanup_test_data():
    """æ¸…ç†æ¸¬è©¦æ•¸æ“š"""
    print("\n=== æ¸…ç†æ¸¬è©¦æ•¸æ“š ===")
    
    import shutil
    test_dirs = [
        "./data/test_vector_db",
        "./data/test_rag_db"
    ]
    
    for test_dir in test_dirs:
        if os.path.exists(test_dir):
            try:
                shutil.rmtree(test_dir)
                print(f"âœ“ æ¸…ç† {test_dir}")
            except Exception as e:
                print(f"âœ— æ¸…ç† {test_dir} å¤±æ•—: {str(e)}")


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("RAG ç³»çµ±æ¸¬è©¦")
    print("=" * 50)
    
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(level=logging.WARNING)  # æ¸›å°‘æ—¥èªŒè¼¸å‡º
    
    test_results = []
    
    # é‹è¡Œæ¸¬è©¦
    tests = [
        ("ç’°å¢ƒé…ç½®", test_environment),
        ("ä¾è³´åŒ…", test_dependencies),
        ("BGE-M3 åµŒå…¥", test_bge_embeddings),
        ("GPT-4o ç”Ÿæˆå™¨", test_gpt4o_generator),
        ("å‘é‡å­˜å„²", test_vector_store),
        ("å®Œæ•´ RAG ç³»çµ±", test_rag_system)
    ]
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name} æ¸¬è©¦ç•°å¸¸: {str(e)}")
            test_results.append((test_name, False))
    
    # æ¸…ç†æ¸¬è©¦æ•¸æ“š
    cleanup_test_data()
    
    # ç¸½çµçµæœ
    print("\n" + "=" * 50)
    print("æ¸¬è©¦çµæœç¸½çµ:")
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ é€šé" if result else "âœ— å¤±æ•—"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} å€‹æ¸¬è©¦é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼RAG ç³»çµ±é…ç½®æ­£ç¢ºã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®å’Œä¾è³´ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
