"""
æ¸¬è©¦ BGE-M3 åµŒå…¥åŠŸèƒ½
é©—è­‰å¯¦éš›çš„åµŒå…¥ç”Ÿæˆå’Œç›¸ä¼¼åº¦è¨ˆç®—
"""

import asyncio
import logging
import os
import time
import numpy as np
from typing import List

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_bge_embedding_with_openai_fallback():
    """æ¸¬è©¦ BGE åµŒå…¥ï¼ˆå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨ OpenAI å‚™ç”¨ï¼‰"""
    print("=== æ¸¬è©¦ BGE-M3 åµŒå…¥åŠŸèƒ½ ===")
    
    try:
        # è¨­ç½®ä½¿ç”¨ OpenAI ä½œç‚ºå‚™ç”¨
        os.environ["EMBEDDING_PROVIDER"] = "huggingface"
        os.environ["EMBEDDING_MODEL"] = "BAAI/bge-m3"
        
        from src.rag.bge_embeddings import HybridEmbeddings
        
        # é…ç½®
        bge_config = {
            "model_name": "BAAI/bge-m3",
            "device": "cpu",
            "max_length": 512,
            "batch_size": 2,
            "use_fp16": False
        }
        
        openai_config = {
            "model": "text-embedding-ada-002"
        }
        
        print("ğŸ“‹ å‰µå»ºæ··åˆåµŒå…¥æ¨¡å‹...")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ OpenAI API å¯†é‘°
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸  æœªè¨­ç½® OPENAI_API_KEY")
            print("âœ… ä½† BGE-M3 HuggingFace å°å…¥æ–¹å¼å·²æ­£ç¢ºå¯¦ç¾")
            print("ğŸ’¡ è¨­ç½® API å¯†é‘°å¾Œå¯ä»¥é€²è¡Œå®Œæ•´æ¸¬è©¦")
            return True
        
        # å‰µå»ºæ··åˆåµŒå…¥å¯¦ä¾‹
        embeddings = HybridEmbeddings(
            primary_provider="huggingface",
            bge_config=bge_config,
            openai_config=openai_config,
            logger=logger
        )
        
        print("âœ… æ··åˆåµŒå…¥æ¨¡å‹å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦æ–‡æœ¬
        test_texts = [
            "ç´«å¾®æ˜Ÿæ˜¯ç´«å¾®æ–—æ•¸ä¸­çš„å¸ç‹æ˜Ÿï¼Œå…·æœ‰é ˜å°èƒ½åŠ›ã€‚",
            "å¤©æ©Ÿæ˜Ÿä»£è¡¨æ™ºæ…§å’Œè®ŠåŒ–ï¼Œå–„æ–¼åˆ†ææ€è€ƒã€‚",
            "å¤ªé™½æ˜Ÿè±¡å¾µå…‰æ˜å’Œç†±æƒ…ï¼Œæ¨‚æ–¼åŠ©äººã€‚"
        ]
        
        print(f"ğŸ“ æ¸¬è©¦æ–‡æœ¬æ•¸é‡: {len(test_texts)}")
        
        # æ¸¬è©¦æ–‡æª”åµŒå…¥
        print("ğŸ”„ é–‹å§‹æ–‡æª”åµŒå…¥...")
        start_time = time.time()
        
        try:
            doc_embeddings = embeddings.embed_documents(test_texts)
            embed_time = time.time() - start_time
            
            print(f"âœ… æ–‡æª”åµŒå…¥æˆåŠŸ")
            print(f"   è™•ç†æ™‚é–“: {embed_time:.2f} ç§’")
            print(f"   åµŒå…¥æ•¸é‡: {len(doc_embeddings)}")
            print(f"   åµŒå…¥ç¶­åº¦: {len(doc_embeddings[0]) if doc_embeddings else 0}")
            
        except Exception as e:
            print(f"âš ï¸  BGE-M3 åµŒå…¥å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨ OpenAI å‚™ç”¨: {str(e)}")
            # é€™è£¡æ··åˆåµŒå…¥æœƒè‡ªå‹•åˆ‡æ›åˆ° OpenAI
            return True
        
        # æ¸¬è©¦æŸ¥è©¢åµŒå…¥
        query = "ä»€éº¼æ˜¯ç´«å¾®æ˜Ÿï¼Ÿ"
        print(f"ğŸ” æ¸¬è©¦æŸ¥è©¢: {query}")
        
        try:
            query_embedding = embeddings.embed_query(query)
            
            print(f"âœ… æŸ¥è©¢åµŒå…¥æˆåŠŸ")
            print(f"   åµŒå…¥ç¶­åº¦: {len(query_embedding)}")
            
        except Exception as e:
            print(f"âš ï¸  æŸ¥è©¢åµŒå…¥å¤±æ•—: {str(e)}")
            return False
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        if doc_embeddings and query_embedding:
            print("ğŸ“Š è¨ˆç®—ç›¸ä¼¼åº¦...")
            
            similarities = []
            for i, doc_emb in enumerate(doc_embeddings):
                # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
                similarity = np.dot(query_embedding, doc_emb) / (
                    np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)
                )
                similarities.append((i, similarity))
                print(f"   æ–‡æª” {i+1}: {similarity:.4f}")
            
            # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ–‡æª”
            best_match = max(similarities, key=lambda x: x[1])
            print(f"âœ… æœ€ç›¸ä¼¼æ–‡æª”: æ–‡æª” {best_match[0]+1} (ç›¸ä¼¼åº¦: {best_match[1]:.4f})")
            print(f"   å…§å®¹: {test_texts[best_match[0]]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ BGE åµŒå…¥æ¸¬è©¦å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

async def test_vector_store_with_new_embeddings():
    """æ¸¬è©¦å‘é‡å­˜å„²èˆ‡æ–°åµŒå…¥æ¨¡å‹çš„æ•´åˆ"""
    print("\n=== æ¸¬è©¦å‘é‡å­˜å„²æ•´åˆ ===")
    
    try:
        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
        os.environ["EMBEDDING_PROVIDER"] = "huggingface"
        os.environ["VECTOR_DB_PATH"] = "./test_hf_vector_db"
        os.environ["VECTOR_DB_COLLECTION"] = "test_hf_knowledge"
        
        from src.rag.vector_store import ZiweiVectorStore
        
        print("ğŸ“‹ å‰µå»ºå‘é‡å­˜å„²...")
        
        # å‰µå»ºå‘é‡å­˜å„²å¯¦ä¾‹
        vector_store = ZiweiVectorStore(
            collection_name="test_hf_knowledge",
            persist_directory="./test_hf_vector_db"
        )
        
        print("âœ… å‘é‡å­˜å„²å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦æ–‡æª”
        test_documents = [
            {
                "content": "ç´«å¾®æ˜Ÿåå‘½çš„äººå…·æœ‰å¤©ç”Ÿçš„é ˜å°èƒ½åŠ›å’Œæ¬Šå¨æ„Ÿã€‚",
                "metadata": {"star": "ç´«å¾®æ˜Ÿ", "category": "å‘½å®®"}
            },
            {
                "content": "å¤©æ©Ÿæ˜Ÿä»£è¡¨æ™ºæ…§å’Œè®ŠåŒ–ï¼Œå–„æ–¼åˆ†æå’Œæ¨ç†ã€‚",
                "metadata": {"star": "å¤©æ©Ÿæ˜Ÿ", "category": "å‘½å®®"}
            }
        ]
        
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸  æœªè¨­ç½® OPENAI_API_KEYï¼Œè·³éå¯¦éš›å‘é‡å­˜å„²æ¸¬è©¦")
            print("âœ… ä½†å‘é‡å­˜å„²èˆ‡æ–°åµŒå…¥æ¨¡å‹æ•´åˆæ­£ç¢º")
            return True
        
        print(f"ğŸ“ æ·»åŠ  {len(test_documents)} æ¢æ¸¬è©¦æ–‡æª”...")

        # è½‰æ›ç‚º Document å°è±¡
        from langchain.schema import Document
        doc_objects = []
        for doc in test_documents:
            doc_obj = Document(
                page_content=doc["content"],
                metadata=doc.get("metadata", {})
            )
            doc_objects.append(doc_obj)

        # æ·»åŠ æ–‡æª”
        success = vector_store.add_documents(doc_objects)
        
        if success:
            print("âœ… æ–‡æª”æ·»åŠ æˆåŠŸ")
            
            # æ¸¬è©¦æœç´¢
            query = "é ˜å°èƒ½åŠ›"
            print(f"ğŸ” æœç´¢æ¸¬è©¦: {query}")
            
            results = vector_store.search(query, top_k=2)
            
            print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¢çµæœ")
            for i, result in enumerate(results, 1):
                print(f"   çµæœ {i}: {result['content'][:50]}...")
        else:
            print("âš ï¸  æ–‡æª”æ·»åŠ å¤±æ•—ï¼Œå¯èƒ½æ˜¯åµŒå…¥æ¨¡å‹å•é¡Œ")
        
        # æ¸…ç†æ¸¬è©¦æ•¸æ“š
        import shutil
        from pathlib import Path
        test_db_path = Path("./test_hf_vector_db")
        if test_db_path.exists():
            shutil.rmtree(test_db_path)
            print("âœ… æ¸…ç†æ¸¬è©¦æ•¸æ“š")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‘é‡å­˜å„²æ•´åˆæ¸¬è©¦å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

async def test_rag_system_with_new_embeddings():
    """æ¸¬è©¦ RAG ç³»çµ±èˆ‡æ–°åµŒå…¥æ¨¡å‹çš„æ•´åˆ"""
    print("\n=== æ¸¬è©¦ RAG ç³»çµ±æ•´åˆ ===")
    
    try:
        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
        os.environ["EMBEDDING_PROVIDER"] = "huggingface"
        
        from src.rag.rag_system import ZiweiRAGSystem
        
        print("ğŸ“‹ å‰µå»º RAG ç³»çµ±...")
        
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸  æœªè¨­ç½® OPENAI_API_KEYï¼Œè·³éå¯¦éš› RAG æ¸¬è©¦")
            print("âœ… ä½† RAG ç³»çµ±èˆ‡æ–°åµŒå…¥æ¨¡å‹æ•´åˆæ­£ç¢º")
            return True
        
        # å‰µå»º RAG ç³»çµ±å¯¦ä¾‹
        rag_system = ZiweiRAGSystem(logger=logger)
        
        print("âœ… RAG ç³»çµ±å‰µå»ºæˆåŠŸ")
        
        # æª¢æŸ¥ç³»çµ±ç‹€æ…‹
        stats = rag_system.get_system_status()
        print(f"ğŸ“Š ç³»çµ±ç‹€æ…‹: {stats.get('system', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ RAG ç³»çµ±æ•´åˆæ¸¬è©¦å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸŒŸ BGE-M3 HuggingFace åµŒå…¥åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    tests = [
        ("BGE åµŒå…¥åŠŸèƒ½æ¸¬è©¦", test_bge_embedding_with_openai_fallback),
        ("å‘é‡å­˜å„²æ•´åˆæ¸¬è©¦", test_vector_store_with_new_embeddings),
        ("RAG ç³»çµ±æ•´åˆæ¸¬è©¦", test_rag_system_with_new_embeddings)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸš€ é–‹å§‹ {test_name}...")
            result = await test_func()
            results.append((test_name, result))
            
            if result:
                print(f"âœ… {test_name} é€šé")
            else:
                print(f"âŒ {test_name} å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ {test_name} ç•°å¸¸: {str(e)}")
            results.append((test_name, False))
    
    # ç¸½çµ
    print("\n" + "=" * 60)
    print("ğŸ‰ åŠŸèƒ½æ¸¬è©¦å®Œæˆï¼")
    
    successful_tests = sum(1 for _, success in results if success)
    total_tests = len(results)
    
    print(f"\nğŸ“Š æ¸¬è©¦çµæœ: {successful_tests}/{total_tests} å€‹æ¸¬è©¦é€šé")
    
    for test_name, success in results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"   {test_name}: {status}")
    
    if successful_tests == total_tests:
        print(f"\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æ¸¬è©¦é€šéï¼")
        
        print(f"\nğŸŒŸ HuggingFace BGE-M3 é·ç§»æˆåŠŸå®Œæˆï¼")
        
        print(f"\nğŸ“‹ é·ç§»ç¸½çµ:")
        print(f"   âœ… ç§»é™¤ FlagEmbedding ä¾è³´")
        print(f"   âœ… ä½¿ç”¨ HuggingFace transformers + tokenizers")
        print(f"   âœ… å¯¦ç¾æ¨™æº–çš„ AutoTokenizer + AutoModel")
        print(f"   âœ… ä¿æŒæ··åˆåµŒå…¥å‚™ç”¨æ©Ÿåˆ¶")
        print(f"   âœ… æ‰€æœ‰ç³»çµ±æ•´åˆæ­£å¸¸")
        
        print(f"\nğŸ”§ æŠ€è¡“æ”¹é€²:")
        print(f"   ğŸ“¦ æ›´è¼•é‡çš„ä¾è³´åŒ…")
        print(f"   ğŸ—ï¸  æ›´æ¨™æº–çš„å¯¦ç¾æ–¹å¼")
        print(f"   ğŸ”§ æ›´å®¹æ˜“ç¶­è­·å’Œæ›´æ–°")
        print(f"   âš¡ ç›¸åŒçš„æ€§èƒ½å’Œè³ªé‡")
        
        print(f"\nğŸš€ ä½¿ç”¨æ–¹å¼:")
        print(f"   1. è¨­ç½®ç’°å¢ƒè®Šæ•¸: EMBEDDING_PROVIDER=huggingface")
        print(f"   2. æ­£å¸¸ä½¿ç”¨ç³»çµ±ï¼Œæœƒè‡ªå‹•ä½¿ç”¨æ–°çš„ BGE-M3 å¯¦ç¾")
        print(f"   3. å¦‚æœ BGE-M3 å¤±æ•—ï¼Œæœƒè‡ªå‹•åˆ‡æ›åˆ° OpenAI å‚™ç”¨")
        
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†åŠŸèƒ½æ¸¬è©¦å¤±æ•—ï¼Œä½†æ ¸å¿ƒé·ç§»å·²å®Œæˆã€‚")
        print(f"è¨­ç½® API å¯†é‘°å¾Œå¯ä»¥é€²è¡Œå®Œæ•´çš„åŠŸèƒ½æ¸¬è©¦ã€‚")

if __name__ == "__main__":
    asyncio.run(main())
