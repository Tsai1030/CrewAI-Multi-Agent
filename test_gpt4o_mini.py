"""
æ¸¬è©¦ GPT-4o Mini æ¨¡å‹é…ç½®
"""

import asyncio
import os
from src.config.settings import get_settings
from src.rag.gpt4o_generator import GPT4oGenerator
from src.output.gpt4o_formatter import GPT4oFormatter

async def test_gpt4o_mini_config():
    """æ¸¬è©¦ GPT-4o Mini é…ç½®"""
    print("ğŸ§ª æ¸¬è©¦ GPT-4o Mini æ¨¡å‹é…ç½®")
    print("=" * 50)
    
    try:
        # 1. æª¢æŸ¥é…ç½®è¨­å®š
        settings = get_settings()
        print(f"ğŸ“‹ é…ç½®æª¢æŸ¥:")
        print(f"  - OpenAI API Key: {'å·²è¨­ç½®' if settings.openai.api_key else 'æœªè¨­ç½®'}")
        print(f"  - æ¨¡å‹åç¨±: {settings.openai.model_gpt4o}")
        print(f"  - Base URL: {settings.openai.base_url}")
        
        # 2. æ¸¬è©¦ GPT-4o ç”Ÿæˆå™¨
        print(f"\nğŸ”§ æ¸¬è©¦ GPT-4o ç”Ÿæˆå™¨...")
        generator = GPT4oGenerator()
        print(f"  - ç”Ÿæˆå™¨æ¨¡å‹: {generator.model}")
        
        # 3. æ¸¬è©¦ GPT-4o æ ¼å¼åŒ–å™¨
        print(f"\nğŸ“ æ¸¬è©¦ GPT-4o æ ¼å¼åŒ–å™¨...")
        formatter = GPT4oFormatter()
        print(f"  - æ ¼å¼åŒ–å™¨æ¨¡å‹: {formatter.model}")
        
        # 4. ç°¡å–®çš„ API æ¸¬è©¦
        print(f"\nğŸš€ åŸ·è¡Œç°¡å–® API æ¸¬è©¦...")
        
        test_response = await generator.client.chat.completions.create(
            model=generator.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ¸¬è©¦åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": "è«‹ç°¡å–®å›ç­”ï¼šä½ ä½¿ç”¨çš„æ˜¯ä»€éº¼æ¨¡å‹ï¼Ÿ"}
            ],
            max_tokens=100,
            temperature=0.1
        )
        
        response_text = test_response.choices[0].message.content
        print(f"  - API å›æ‡‰: {response_text}")
        print(f"  - ä½¿ç”¨æ¨¡å‹: {test_response.model}")
        
        # 5. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        print(f"\nğŸŒ ç’°å¢ƒè®Šæ•¸æª¢æŸ¥:")
        print(f"  - OPENAI_MODEL_GPT4O: {os.getenv('OPENAI_MODEL_GPT4O', 'æœªè¨­ç½®')}")
        print(f"  - OPENAI_API_KEY: {'å·²è¨­ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè¨­ç½®'}")
        
        print(f"\nâœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print(f"ğŸ¯ ç¢ºèªä½¿ç”¨æ¨¡å‹: {generator.model}")
        
        if "gpt-4o-mini" in generator.model.lower():
            print(f"ğŸ‰ æˆåŠŸåˆ‡æ›åˆ° GPT-4o Miniï¼")
        else:
            print(f"âš ï¸  æ¨¡å‹å¯èƒ½æœªæ­£ç¢ºåˆ‡æ›ï¼Œç•¶å‰: {generator.model}")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()

async def test_cost_comparison():
    """æ¸¬è©¦æˆæœ¬æ¯”è¼ƒ"""
    print(f"\nğŸ’° GPT-4o vs GPT-4o Mini æˆæœ¬æ¯”è¼ƒ:")
    print(f"=" * 40)
    
    # å‡è¨­çš„æˆæœ¬æ•¸æ“šï¼ˆå¯¦éš›æ•¸æ“šè«‹åƒè€ƒ OpenAI å®˜ç¶²ï¼‰
    gpt4o_cost = {
        "input": 0.005,   # æ¯ 1K tokens
        "output": 0.015   # æ¯ 1K tokens
    }
    
    gpt4o_mini_cost = {
        "input": 0.00015,  # æ¯ 1K tokens  
        "output": 0.0006   # æ¯ 1K tokens
    }
    
    # å‡è¨­ä¸€æ¬¡åˆ†æçš„ token ä½¿ç”¨é‡
    typical_usage = {
        "input_tokens": 2000,
        "output_tokens": 1500
    }
    
    # è¨ˆç®—æˆæœ¬
    gpt4o_total = (typical_usage["input_tokens"] / 1000 * gpt4o_cost["input"] + 
                   typical_usage["output_tokens"] / 1000 * gpt4o_cost["output"])
    
    gpt4o_mini_total = (typical_usage["input_tokens"] / 1000 * gpt4o_mini_cost["input"] + 
                        typical_usage["output_tokens"] / 1000 * gpt4o_mini_cost["output"])
    
    savings = gpt4o_total - gpt4o_mini_total
    savings_percent = (savings / gpt4o_total) * 100
    
    print(f"ğŸ“Š å–®æ¬¡åˆ†ææˆæœ¬æ¯”è¼ƒ:")
    print(f"  - GPT-4o: ${gpt4o_total:.4f}")
    print(f"  - GPT-4o Mini: ${gpt4o_mini_total:.4f}")
    print(f"  - ç¯€çœ: ${savings:.4f} ({savings_percent:.1f}%)")
    
    print(f"\nğŸ“ˆ 100æ¬¡åˆ†ææˆæœ¬:")
    print(f"  - GPT-4o: ${gpt4o_total * 100:.2f}")
    print(f"  - GPT-4o Mini: ${gpt4o_mini_total * 100:.2f}")
    print(f"  - ç¯€çœ: ${savings * 100:.2f}")

if __name__ == "__main__":
    asyncio.run(test_gpt4o_mini_config())
    asyncio.run(test_cost_comparison())
